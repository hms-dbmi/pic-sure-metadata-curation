{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa81d557",
   "metadata": {},
   "source": [
    "# Activ4b dataset decoding\n",
    "The datasets of Activ4b (phs002710) were provided as CSV files that contained encoded data. For the BioData Catalyst PIC-SURE ETL pipeline, these files need to be in the decoded format. The purpose of this notebook is to use the Data Dictionary, provided in Excel format, to decode the CSV files and save them to the S3 bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cf2854",
   "metadata": {},
   "source": [
    "## Do imports and set user-defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7a9752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do imports\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5faba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directories and get file information\n",
    "data_dict_path = \"/home/ec2-user/SageMaker/pic-sure-metadata-curation/activ4b/input/DataDict.xlsx\"\n",
    "file_dir = \"/home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4b/development_raw_data/*\"\n",
    "out_dir = \"/home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4b/decoded_data/\"\n",
    "file_prefixes = [i.split('/')[-1].strip(\".csv\") for i in glob.glob(file_dir)]\n",
    "files_to_remove = ['CM', 'DS', 'HO', 'INT', 'LABCONV', 'LB', 'RETURN', 'RSK', 'TA', 'VAC']\n",
    "for i in files_to_remove:\n",
    "    file_prefixes.remove(i)\n",
    "print(file_prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608da8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_data(data_dict_path, file_prefixes, file_dir, out_dir, to_pop=None):\n",
    "    for f in file_prefixes:\n",
    "        data_dict = pd.read_excel(data_dict_path, \n",
    "                      sheet_name = f, \n",
    "                      engine = \"openpyxl\")\n",
    "        data_dict = data_dict.dropna(subset=[\"code\"]).reset_index(drop=True)\n",
    "        data_dict['code'] = data_dict['code'].astype('str') \n",
    "        full_dict = make_decode_dict(data_dict, to_pop)\n",
    "        try:\n",
    "            data = pd.read_csv(file_dir.strip(\"*\")+f+\".csv\")\n",
    "        except:\n",
    "            print(\"Review data of\", f)\n",
    "            continue\n",
    "        try: \n",
    "            decoded_data = data.replace(full_dict)\n",
    "        except:\n",
    "            print(\"Review data dictionary of\", f)\n",
    "            print(\"Unsuccessful\")\n",
    "            continue\n",
    "        out_file = out_dir+f+\".csv\"\n",
    "        decoded_data.to_csv(out_file, index=False)\n",
    "        print(\"Decoded dataset\", out_file)\n",
    "        \n",
    "def make_decode_dict(df, pop_val):\n",
    "    full_dict = {}\n",
    "    for var in df.VARNAME:\n",
    "        data = df.code[df.VARNAME == var].values[0]\n",
    "        list_data = data.split(\"|\")\n",
    "        mini_dict = {}\n",
    "        for info in list_data:\n",
    "            mapping = info.split(\"=\")\n",
    "            try:\n",
    "                encoded_val = int(mapping[0])\n",
    "            except:\n",
    "                encoded_val = int(mapping[0].strip().strip(\"'\"))\n",
    "            if (pop_val is not None and encoded_val not in pop_val) or pop_val is None:\n",
    "                decoded_val = mapping[1].strip().strip(\"'\")\n",
    "                mini_dict.update({encoded_val: decoded_val})\n",
    "        full_dict.update({var: mini_dict})\n",
    "    return full_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcae8c3",
   "metadata": {},
   "source": [
    "## Use functions to decode the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104cc290",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decode_data(data_dict_path, [''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7371d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_data(data_dict_path, file_prefixes, file_dir, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eaf162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used as needed to remove problematic files\n",
    "#file_prefixes.remove(\"ADJ_VT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd59964",
   "metadata": {},
   "source": [
    "## Look into problematic files\n",
    "The following files had issues when trying to run the `decode_data` function:\n",
    "- ADJ_TIMING\n",
    "- ADJ_STROKE\n",
    "- ADJ_VT\n",
    "\n",
    "The following files need data dictionary review:\n",
    "- ADJ_BLEEDING\n",
    "- ADJ_DIC\n",
    "- ADJ_MI\n",
    "- ADJ_PE\n",
    "\n",
    "The following files were not included in the data dictionary and thus were excluded from decoding:\n",
    "- CM\n",
    "- DS\n",
    "- HO\n",
    "- INT\n",
    "- LABCONV\n",
    "- LB\n",
    "- RETURN\n",
    "- RSK\n",
    "- TA\n",
    "- VAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcd76da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigating the files that need data dictionary review\n",
    "decode_data(data_dict_path, ['ADJ_BLEEDING'], file_dir, out_dir)\n",
    "decode_data(data_dict_path, ['ADJ_DIC'], file_dir, out_dir)\n",
    "decode_data(data_dict_path, ['ADJ_MI'], file_dir, out_dir)\n",
    "decode_data(data_dict_path, ['ADJ_PE'], file_dir, out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c85aa3",
   "metadata": {},
   "source": [
    "Upon further investigation, some of the data dictionary encoded values were recorded as strings (for example, `'1'` instead of `1`). To deal with this, the `make_data_dict` function was edited to convert these strings to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067d5511",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_data(data_dict_path, ['ADJ_TIMING'], file_dir, out_dir)\n",
    "decode_data(data_dict_path, ['ADJ_STROKE'], file_dir, out_dir)\n",
    "#decode_data(data_dict_path, ['ADJ_VT'], file_dir, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6de1c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigating the files that break the decode_data function (ADJ_VT) \n",
    "f = 'ADJ_VT'\n",
    "to_pop = ['defpres_cec ']\n",
    "data_dict = pd.read_excel(data_dict_path, \n",
    "                      sheet_name = f, \n",
    "                      engine = \"openpyxl\")\n",
    "data_dict = data_dict.dropna(subset=[\"code\"]).reset_index(drop=True)\n",
    "data_dict['code'] = data_dict['code'].astype('str')\n",
    "raw_data = pd.read_csv(file_dir.strip(\"*\")+f+\".csv\")\n",
    "full_dict = {}\n",
    "for var in data_dict.VARNAME:\n",
    "    data = data_dict.code[data_dict.VARNAME == var].values[0]\n",
    "    list_data = data.split(\"|\")\n",
    "    mini_dict = {}\n",
    "    for info in list_data:\n",
    "        mapping = info.split(\"=\")\n",
    "        if mapping[0] != to_pop[0]:\n",
    "            #print(mapping[0])\n",
    "            try:\n",
    "                encoded_val = int(mapping[0])\n",
    "            except:\n",
    "                try:\n",
    "                    encoded_val = int(mapping[0].strip().strip(\"'\"))\n",
    "                except:\n",
    "                    encoded_val = mapping[0].strip().strip(\"'\")\n",
    "            if (pop_val is not None and encoded_val not in pop_val) or pop_val is None:\n",
    "                decoded_val = mapping[1].strip().strip(\"'\")\n",
    "                mini_dict.update({encoded_val: decoded_val})\n",
    "    full_dict.update({var: mini_dict})\n",
    "decoded_data = raw_data.replace(full_dict)\n",
    "out_file = out_dir+f+\".csv\"\n",
    "decoded_data.to_csv(out_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
