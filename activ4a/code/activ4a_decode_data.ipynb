{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a38b199",
   "metadata": {},
   "source": [
    "## Activ4a dataset decoding\n",
    "\n",
    "The datasets of Activ4a (phs002694) were provided as CSV files that contained encoded data. For the BioData Catalyst PIC-SURE ETL pipeline, these files need to be in the decoded format. The purpose of this notebook is to use the Data Dictionary, provided in Excel format, to decode the CSV files and save them to the S3 bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e5e61a",
   "metadata": {},
   "source": [
    "### Do imports, set directory paths, and define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3235905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do imports\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df7ce2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directories and get file information\n",
    "data_dict_path = \"/home/ec2-user/SageMaker/pic-sure-metadata-curation/activ4a/input/Data Dictionary 2022-01-04.xlsx\"\n",
    "file_dir = \"/home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_raw_data/*\"\n",
    "out_dir = \"/home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_decoded_data/\"\n",
    "file_prefixes = [i.split('/')[-1].strip(\".csv\") for i in glob.glob(file_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19a4a02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_data(data_dict_path, file_prefixes, file_dir, out_dir, to_pop=None):\n",
    "    for f in file_prefixes:\n",
    "        data_dict = pd.read_excel(data_dict_path, \n",
    "                      sheet_name = f, \n",
    "                      engine = \"openpyxl\")\n",
    "        data_dict = data_dict.dropna(subset=[\"code\"]).reset_index(drop=True)\n",
    "        data_dict['code'] = data_dict['code'].astype('str') \n",
    "        full_dict = make_decode_dict(data_dict, to_pop)\n",
    "        try:\n",
    "            data = pd.read_csv(file_dir.strip(\"*\")+f+\".csv\")\n",
    "        except:\n",
    "            print(\"Review data of\", f)\n",
    "            continue\n",
    "        try: \n",
    "            decoded_data = data.replace(full_dict)\n",
    "        except:\n",
    "            print(\"Review data dictionary of\", f)\n",
    "            print(\"Unsuccessful\")\n",
    "            continue\n",
    "        out_file = out_dir+f+\".csv\"\n",
    "        decoded_data.to_csv(out_file, index=False)\n",
    "        print(\"Decoded dataset\", out_file)\n",
    "        \n",
    "def make_decode_dict(df, pop_val):\n",
    "    full_dict = {}\n",
    "    for var in df.VARNAME:\n",
    "        data = df.code[df.VARNAME == var].values[0]\n",
    "        list_data = data.split(\"|\")\n",
    "        mini_dict = {}\n",
    "        for info in list_data:\n",
    "            mapping = info.split(\"=\")\n",
    "            try:\n",
    "                encoded_val = int(mapping[0])\n",
    "            except:\n",
    "                encoded_val = mapping[0].strip().strip(\"'\")\n",
    "            if (pop_val is not None and encoded_val not in pop_val) or pop_val is None:\n",
    "                decoded_val = mapping[1].strip().strip(\"'\")\n",
    "                mini_dict.update({encoded_val: decoded_val})\n",
    "        full_dict.update({var: mini_dict})\n",
    "    return full_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffc65c6",
   "metadata": {},
   "source": [
    "### Use functions to decode the data\n",
    "Note that based on the output, there were some files that we were not able to decode without some manual curation. These were:\n",
    "- ADJ_STROKE\n",
    "- BIOREP\n",
    "- CMBL\n",
    "- CONS\n",
    "- HS\n",
    "- IE\n",
    "- LBRES\n",
    "- OUTCOME\n",
    "- REHOSP\n",
    "- SAMPLE\n",
    "- SD\n",
    "- STATUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91f225cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded dataset /home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_decoded_data/ADJ_ATE.csv\n",
      "Decoded dataset /home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_decoded_data/ADJ_BLEEDING.csv\n",
      "Decoded dataset /home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_decoded_data/ADJ_MI.csv\n",
      "Decoded dataset /home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_decoded_data/ADJ_PE.csv\n",
      "Review data dictionary of ADJ_STROKE\n",
      "Unsuccessful\n",
      "Decoded dataset /home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_decoded_data/ADJ_VT.csv\n",
      "Review data dictionary of AE\n",
      "Unsuccessful\n",
      "Review data dictionary of BIOREP\n",
      "Unsuccessful\n",
      "Decoded dataset /home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_decoded_data/CALL.csv\n",
      "Decoded dataset /home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_decoded_data/CMBL.csv\n",
      "Review data dictionary of CONS\n",
      "Unsuccessful\n",
      "Decoded dataset /home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_decoded_data/CT.csv\n",
      "Decoded dataset /home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_decoded_data/DD.csv\n",
      "Decoded dataset /home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_decoded_data/EQ5D.csv\n",
      "Decoded dataset /home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_decoded_data/HO.csv\n",
      "Decoded dataset /home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_decoded_data/HORES.csv\n",
      "Review data dictionary of HS\n",
      "Unsuccessful\n",
      "Review data dictionary of IE\n",
      "Unsuccessful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3263: DtypeWarning: Columns (3,12,13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review data dictionary of LBRES\n",
      "Unsuccessful\n",
      "Decoded dataset /home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_decoded_data/MH.csv\n",
      "Decoded dataset /home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_decoded_data/MPRCT.csv\n",
      "Review data dictionary of OUTCOME\n",
      "Unsuccessful\n",
      "Decoded dataset /home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_decoded_data/PROB.csv\n",
      "Decoded dataset /home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_decoded_data/REHOSP.csv\n",
      "Review data dictionary of SAMPLE\n",
      "Unsuccessful\n",
      "Review data dictionary of SD\n",
      "Unsuccessful\n",
      "Review data dictionary of STATUS\n",
      "Unsuccessful\n",
      "Decoded dataset /home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_decoded_data/VS.csv\n",
      "Decoded dataset /home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_decoded_data/WITHDSC.csv\n",
      "Decoded dataset /home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_decoded_data/WITHDTX.csv\n"
     ]
    }
   ],
   "source": [
    "decode_data(data_dict_path, file_prefixes, file_dir, out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277fc541",
   "metadata": {},
   "source": [
    "### Manual review of problematic data dictionaries\n",
    "After reviewing the data dictionaries and data files by hand, there were some decoded values that were not in the data and thus causing problems. These included `.U`, `.A`, and `.D`. Since these are strings while the type of the data were numeric, this was causing problems in the `replace` function. Therefore, the functions were adjusted to include an option to exclude these parts of the data dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83378b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to review data dictionary ADJ_STROKE (pop .U), BIOREP (pop .A), CONS (pop .U and .D), HS (pop .U), \n",
    "# IE (pop .A), LBRES (pop .D), SAMPLE (pop .A), SD (pop .D), STATUS (pop .U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f466a6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded dataset /home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_decoded_data/ADJ_STROKE.csv\n",
      "Decoded dataset /home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_decoded_data/HS.csv\n",
      "Decoded dataset /home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_decoded_data/STATUS.csv\n",
      "Decoded dataset /home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_decoded_data/MH.csv\n",
      "Decoded dataset /home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_decoded_data/OUTCOME.csv\n",
      "Decoded dataset /home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_decoded_data/BIOREP.csv\n",
      "Decoded dataset /home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_decoded_data/IE.csv\n",
      "Decoded dataset /home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_decoded_data/SAMPLE.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3263: DtypeWarning: Columns (3,12,13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded dataset /home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_decoded_data/LBRES.csv\n",
      "Decoded dataset /home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_decoded_data/SD.csv\n",
      "Decoded dataset /home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_decoded_data/CONS.csv\n",
      "Decoded dataset /home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_decoded_data/AE.csv\n",
      "Decoded dataset /home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_decoded_data/VS.csv\n"
     ]
    }
   ],
   "source": [
    "u_pop_prefixes = ['ADJ_STROKE', 'HS', 'STATUS', \"MH\", \"OUTCOME\"]\n",
    "a_pop_prefixes = ['BIOREP', 'IE', 'SAMPLE']\n",
    "d_pop_prefixes = ['LBRES',  'SD']\n",
    "ud_pop_prefixes = ['CONS']\n",
    "aud_pop_prefixes = [\"AE\"]\n",
    "ad_pop_prefixes = [\"VS\"]\n",
    "decode_data(data_dict_path, u_pop_prefixes, file_dir, out_dir, to_pop=['.U'])\n",
    "decode_data(data_dict_path, a_pop_prefixes, file_dir, out_dir, to_pop=['.A'])\n",
    "decode_data(data_dict_path, d_pop_prefixes, file_dir, out_dir, to_pop=['.D'])\n",
    "decode_data(data_dict_path, ud_pop_prefixes, file_dir, out_dir, to_pop=['.U', '.D'])\n",
    "decode_data(data_dict_path, aud_pop_prefixes, file_dir, out_dir, to_pop=['.A', '.U', '.D'])\n",
    "decode_data(data_dict_path, ad_pop_prefixes, file_dir, out_dir, to_pop=['.A', '.D'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc76d5b",
   "metadata": {},
   "source": [
    "### Manual review of problematic data\n",
    "After attempting to review the data files on the S3 bucket through Service Workbench, it became obvious that the issue with some of these data files were the encoding. This was resolved by manually saving these files in the \"CSV UTF-8\" format and reuploading them to the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7b409f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded dataset /home/ec2-user/studies/ALL-avillach-73-bdcatalyst-etl/activ4a/development_decoded_data/CMBL.csv\n"
     ]
    }
   ],
   "source": [
    "decode_data(data_dict_path, [\"CMBL\"], file_dir, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea6cdae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review data dictionary of OUTCOME\n",
      "Unsuccessful\n"
     ]
    }
   ],
   "source": [
    "decode_data(data_dict_path, [\"OUTCOME\"], file_dir, out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfa4dca",
   "metadata": {},
   "source": [
    "### Confirm that data was decoded as expected\n",
    "Since there were some unique problems with some of the data files and dictionaries, compare the raw and decoded CSV files to see if they changed.\n",
    "The following files need further investigation:\n",
    "- AE\n",
    "- MH\n",
    "- MPRCT\n",
    "- OUTCOME\n",
    "- VS\n",
    "- WITHDSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7bb76454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_decode(file_dir, out_dir, file_prefixes, out=False):\n",
    "    for f in file_prefixes:\n",
    "        raw_df = pd.read_csv(file_dir.strip(\"*\")+f+\".csv\")\n",
    "        decode_df = pd.read_csv(out_dir+f+\".csv\")\n",
    "        comp = decode_df.compare(raw_df)\n",
    "        if comp.shape[0] == 0:\n",
    "            print(f, \"not decoded properly\")\n",
    "        else:\n",
    "            print(\"Successful\", f)\n",
    "        if out:\n",
    "            return raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4c0ed653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful ADJ_ATE\n",
      "Successful ADJ_BLEEDING\n",
      "Successful ADJ_MI\n",
      "Successful ADJ_PE\n",
      "Successful ADJ_STROKE\n",
      "Successful ADJ_VT\n",
      "Successful AE\n",
      "Successful BIOREP\n",
      "Successful CALL\n",
      "Successful CMBL\n",
      "Successful CONS\n",
      "Successful CT\n",
      "Successful DD\n",
      "Successful EQ5D\n",
      "Successful HO\n",
      "Successful HORES\n",
      "Successful HS\n",
      "Successful IE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3263: DtypeWarning: Columns (3,12,13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful LBRES\n",
      "Successful MH\n",
      "MPRCT not decoded properly\n",
      "Successful OUTCOME\n",
      "Successful PROB\n",
      "Successful REHOSP\n",
      "Successful SAMPLE\n",
      "Successful SD\n",
      "Successful STATUS\n",
      "Successful VS\n",
      "WITHDSC not decoded properly\n",
      "Successful WITHDTX\n"
     ]
    }
   ],
   "source": [
    "check_decode(file_dir, out_dir, file_prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "85469c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful AE\n"
     ]
    }
   ],
   "source": [
    "# Manually check each file\n",
    "#ae = check_decode(file_dir, out_dir, [\"AE\"], True)\n",
    "#cmbl = check_decode(file_dir, out_dir, ['CMBL'], True)\n",
    "#mh = check_decode(file_dir, out_dir, ['MH'], True)\n",
    "#mprct = check_decode(file_dir, out_dir, ['MPRCT'], True)\n",
    "#outcome = check_decode(file_dir, out_dir, ['OUTCOME'], True)\n",
    "#rehosp = check_decode(file_dir, out_dir, ['REHOSP'], True)\n",
    "#vs = check_decode(file_dir, out_dir, ['VS'], True)\n",
    "#withdsc = check_decode(file_dir, out_dir, ['WITHDSC'], True)\n",
    "#withdsc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4578eb2b",
   "metadata": {},
   "source": [
    "### Results from check:\n",
    "- Need to fix cmbl, outcome, rehosp\n",
    "- AE, MH, VS data dictionary and data file do not match\n",
    "    - Note: there were two files hosted on Gen3 for these specific files. This was fixed by uploading the other version of the file to the S3 bucket and rerunning the code.\n",
    "- MPRCT there is no data to decode, all variables are strings or numeric. This file is OK.\n",
    "- WITHDSC is an empty dataframe, therefore no data to decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f9947a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual check of complicated files\n",
    "#f = 'OUTCOME'\n",
    "#to_pop = None\n",
    "#data_dict = pd.read_excel(data_dict_path, sheet_name = f, engine = \"openpyxl\")\n",
    "#data_dict = data_dict.dropna(subset=[\"code\"]).reset_index(drop=True)\n",
    "#data_dict['code'] = data_dict['code'].astype('str') \n",
    "#full_dict = make_decode_dict(data_dict, to_pop)\n",
    "#full_dict = {}\n",
    "#for var in data_dict.VARNAME:\n",
    "#    data = data_dict.code[data_dict.VARNAME == var].values[0]\n",
    "#    list_data = data.split(\"|\")\n",
    "#    print(list_data)\n",
    "#    mini_dict = {}\n",
    "#    #for info in list_data:\n",
    "#    #    mapping = info.split(\"=\")\n",
    "#    #    try:\n",
    "#    #        encoded_val = int(mapping[0])\n",
    "#    #    except:\n",
    "#    #        encoded_val = mapping[0].strip().strip(\"'\")\n",
    "#    #    if (to_pop is not None and encoded_val not in to_pop) or to_pop is None:\n",
    "#    #        decoded_val = mapping[1].strip().strip(\"'\")\n",
    "#    #        mini_dict.update({encoded_val: decoded_val})\n",
    "#    ##print(encoded_val, decoded_val)\n",
    "#    #full_dict.update({var: mini_dict})\n",
    "#print(full_dict)\n",
    "#try:\n",
    "#    data = pd.read_csv(file_dir.strip(\"*\")+f+\".csv\")\n",
    "#except:\n",
    "#    print(\"Review data of\", f)\n",
    "#try: \n",
    "#    decoded_data = data.replace(full_dict)\n",
    "#except:\n",
    "#    print(\"Review data dictionary of\", f)\n",
    "#    print(\"Unsuccessful\")\n",
    "#out_file = out_dir+f+\".csv\"\n",
    "#decoded_data.to_csv(out_file, index=False)\n",
    "#print(\"Decoded dataset\", out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d4d2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
