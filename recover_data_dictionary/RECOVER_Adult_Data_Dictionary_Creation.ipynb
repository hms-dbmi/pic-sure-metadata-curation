{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RECOVER Adult PIC-SURE Data Dictionary \n",
    "This notebook creates the RECOVER Adult Cohort Data Dictionary using the RECOVER data available via the PIC-SURE API through the development environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do installs\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow.feather as feather\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Gather data from PIC-SURE API (or load existing data)\n",
    "In this step, we get:\n",
    "1. PIC-SURE Dictionary for RECOVER Adult cohort\n",
    "2. Participant-level data for RECOVER Adult cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do imports for PIC-SURE API\n",
    "!{sys.executable} -m pip install --upgrade --force-reinstall git+https://github.com/hms-dbmi/pic-sure-python-client.git\n",
    "!{sys.executable} -m pip install --upgrade --force-reinstall git+https://github.com/hms-dbmi/pic-sure-python-adapter-hpds.git\n",
    "!{sys.executable} -m pip install --upgrade --force-reinstall git+https://github.com/hms-dbmi/pic-sure-biodatacatalyst-python-adapter-hpds.git\n",
    "import PicSureClient\n",
    "import PicSureBdcAdapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to PIC-SURE API\n",
    "PICSURE_network_URL = \"https://picsure.biodatacatalyst.nhlbi.nih.gov/picsure\"\n",
    "token_file = \"token.txt\"\n",
    "\n",
    "with open(token_file, \"r\") as f:\n",
    "    my_token = f.read()\n",
    "    \n",
    "bdc = PicSureBdcAdapter.Adapter(PICSURE_network_URL, my_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for RECOVER Adult (phs003463) variables in PIC-SURE Dictionary\n",
    "dictionary = bdc.useDictionary().dictionary() # Set up the dictionary\n",
    "all_variables = dictionary.find(\"phs003463\") # Retrieve all variables you have access to\n",
    "search_vars = all_variables.dataframe()\n",
    "recover_vars = search_vars[search_vars.studyId == \"phs003463\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "halfway = int(len(recover_vars)/2)\n",
    "first_half = recover_vars[0:halfway]\n",
    "second_half = recover_vars[halfway:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get RECOVER Adult data\n",
    "# Note: The RECOVER data is currently too large to export in one query, which is why two queries are created and executed\n",
    "authPicSure = bdc.useAuthPicSure()\n",
    "test_query1 = authPicSure.query()\n",
    "test_query2 = authPicSure.query()\n",
    "test_query1.anyof().add(first_half.HPDS_PATH)\n",
    "test_query2.anyof().add(second_half.HPDS_PATH)\n",
    "recover_results1 = test_query1.getResultsDataFrame(low_memory = False)\n",
    "recover_results2 = test_query2.getResultsDataFrame(low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the results of the two queries\n",
    "recover_results = recover_results1.merge(recover_results2, on = [\"Patient ID\", \"\\\\_Parent Study Accession with Subject ID\\\\\",\n",
    "                                                                 \"\\\\_Topmed Study Accession with Subject ID\\\\\", \"\\\\_consents\\\\\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as files to not rely on dev environment\n",
    "feather.write_feather(recover_results, 'recover_export')\n",
    "feather.write_feather(recover_vars, 'recover_variable_info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load previously saved files\n",
    "recover_vars = feather.read_feather('recover_variable_info')\n",
    "recover_results = feather.read_feather('recover_export')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Data Dictionary - Define Functions\n",
    "Set up the functions to review the data and create the data dictionary.\n",
    "\n",
    "Dataframe  / Data Dictionary plan\n",
    "\n",
    "| Variable / Field Name | Field Label | Dataset | Data Type | Field Attributes | Mapped Instrument | Number of participants |\n",
    "| ------ | ----- | ----- | ----- | ----- | ----- | ----- |\n",
    "| Encoded variable name | Decoded Variable Description | Dataset Name | Continuous or Categorical | Continuous: min/max/mean, Categorical: Date, ID, or # top 6 values | RedCap Instrument mapping | Number of participants with values |\n",
    "| PIC-SURE name | PIC-SURE decoded description | Order enrollment enrollment, then enrollment demographics, then the other enrollment, then the follow up, then biospecimens, then fitbit | PIC-SURE data type | Continuous - only show 2 digits after decimal, Categorical: do top 6 values defined by number of participants with values | Based on document shared | Number of participants with values |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not all columns needed for RECOVER Adult Data dictionary\n",
    "simplified = recover_vars[['columnmeta_var_id', 'columnmeta_description', 'columnmeta_var_group_id', \n",
    "             'columnmeta_var_group_description', 'columnmeta_data_type', 'columnmeta_min', \n",
    "             'columnmeta_max', 'values', 'HPDS_PATH']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with identifying the datasets used to map to instruments from RedCap form\n",
    "# remove extra info in dataset, such as \"enrollment_\", \"followup_XX_\", and \"miscellaneous_form_\"\n",
    "picsure_dt = simplified['columnmeta_var_group_id'].unique()\n",
    "instruments = []\n",
    "for dt in picsure_dt:\n",
    "    instrum = re.sub(\"enrollment_|followup_\\d{1,2}_|miscellaneous_form_|_baseline_arm_\\d{1,2}|_followup_\\d{1,2}_arm_\\d{1,2}\", '', dt)\n",
    "    if instrum not in instruments:\n",
    "        instruments.append(instrum)\n",
    "\n",
    "for i in instruments:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map to RedCap instruments manually with human-readable name\n",
    "instrument_mapping = {\n",
    "                      \"alcohol_and_tobacco\": \"Alcohol and Tobacco\",\n",
    "                      \"assessment_scores\": \"Assessment Scores\", \"covid_treatment\": \"COVID Treatment\",\n",
    "                      \"demographics\": \"Demographics\", \"disability\": \"Disability\", \n",
    "                      \"enrollment\": \"Enrollment\", \"long_covid_treatment_trial\": \"Long COVID Treatment\",\n",
    "                      \"pasc_symptoms\": \"PASC Symptoms\", \"pregnancy\": \"Pregnancy\", \n",
    "                      \"recent_covid_treatment\": \"Recent COVID Treatment\", \"social_determinants_of_health\": \"Social Determinants of Health\",\n",
    "                      \"tier_12_consent_tracking\":\"Tier 1-2 consent tracking\", \"withdrawal\":\"Withdrawal\",\n",
    "                      \"alcohol_and_tobacco_followup\": \"Alcohol and Tobacco (Followup)\", \"new_covid_infection\": \"New COVID Infection\",\n",
    "                      \"pregnancy_followup\":\"Pregnancy (Followup)\", \"visit_form\": \"Visit form\",\n",
    "                      \"end_of_participation\":\"End Of Participation\", \"study_termination\": \"Study termination\",\n",
    "                      \"psg_quality_summary_form\": \"PSG Quality Summary Form\", \n",
    "                      \"facility_sleep_study\": \"Facility Sleep Study\", \"neonatal_delivery_and_outcome_form\":\"Neonatal Delivery and Outcome Form\",\n",
    "                      \"oral_glucose_test\": \"Oral Glucose Test\", \"colonoscopy\":\"Colonoscopy\", \"fibroscan\": \"Fibroscan\",\n",
    "                      \"cardiac_mri_reading_center\": \"Cardiac MRI Reading Center\", \"clinical_labs\": \"Clinical Labs\",\n",
    "                      \"research_labs\": \"Research Labs\", \"tier_1_office_visit\": \"Tier 1 Office Visit\", \"echocardiogram_with_strain\":\"Echocardiogram\",\n",
    "                      \"pft_reading_center\": \"PFT Reading Center\", \"acth_and_cortisol_test\": \"ACTH and Cortisol Test\",\n",
    "                      \"home_sleep_assessment\": \"Home Sleep Assessment\", \"biospecimens\": \"Biospecimens\",\n",
    "                      \"sleep_reading_center\": \"Sleep Reading Center\", \"adult_delivery_and_outcome_form\":\"Adult Delivery and Outcome Form\",\n",
    "                      \"formal_neuropsychological_testing\": \"Full neurocognitive testing\", \"comprehensive_audiometry\": \"Comprehensive Audiometry\",\n",
    "                      \"nih_toolbox\": \"NIH Toolbox\", \"brain_mri_with_gadolinium\": \"Brain MRI\", \"brain_mri_quality_confirmation\": \"Brain MRI Quality Confirmation\",\n",
    "                      \"neuropathy_examination\":\"Neuropathy Examination\", \"six_minute_walk_test\": \"Six Minute Walk Test\",\n",
    "                      \"electrocardiogram\": \"Electrocardiogram\", \"social_determinants_of_health_followup\":\"Social Determinants of Health (Followup)\",\n",
    "                      \"endopat_testing\":\"Endopat Testing\", \"chest_ct_reading_center\": \"Chest CT Reading Center\",\n",
    "                      \"comorbidities\": \"Comorbidities\", \"pcl5\":\"PCL5\", \"disability\": \"Disability\", \"chest_ct\":\"Chest CT\",\n",
    "                      \"cardiac_mri\":\"Cardiac MRI\", \"renal_ultrasound\":\"Renal Ultrasound\", \"cardiopulmonary_exercise_testing\":\"Cardiopulmonary Exercise Testing\",\n",
    "                      \"pulmonary_function_tests\": \"Pulmonary Function Tests\", \"rehabilitation_testing\":\"Rehabilitation Testing\",\n",
    "                      \"full_ent_examination\":\"Full ENT Examination\", \"gastric_emptying_study\":\"Gastric Emptying Study\", \n",
    "                      \"hepatitis_tests\": \"Hepatitis Tests\", \"home_polysomnography_with_ess_and_isi\": \"Home Polysomnography With ESS and ISI\",\n",
    "                      \"serum_b12_and_methylmalonic_acid\": \"Serum B12 And Methylmalonic Acid\", \"mini\":\"MINI\",\n",
    "                      \"mini_prequestionnaire\": \"MINI Prequestionnaire\", \"pg13r\":\"PG13r\", \"upsit_smell_test\":\"UPSIT Smell Test\",\n",
    "                      \"vaccine_status\":\"Vaccine Status\", \"vision_testing\":\"Vision Testing\", \"change_in_symptoms_since_infection\":\"Change In Symptoms Since Infection\",\n",
    "                      \"cpet_reading_center\":\"CPET Reading Center\", \"medication_changes\":\"Medication Changes\",\n",
    "                      \"mhp_data\":\"MHP Data\", \"medications\":\"Medications\", \"wearable_data\":\"Wearable Data\",\n",
    "                      \"audiometry_survey\":\"Audiometry Survey\", \"cardiovagal_innervation_testing\":\"Cardiovagal Innervation Testing\",\n",
    "                      \"electromyography\":\"Electromyography\", \"nerve_conduction_study\":\"Nerve Conduction Study\",\n",
    "                      \"plasma_catecholamine_testing\": \"Plasma Catecholamine Testing\", \"skin_biopsy\":\"Skin Biopsy\",\n",
    "                      \"tilt_table_test\": \"Tilt Table Test\", \"drc_data\": \"DRC Data\",\n",
    "                      \"facility_sleep_questionnaire_morning_after\":\"Facility Sleep Questionnaire Morning After\",\n",
    "                      \"facility_sleep_questionnaire_night_before\":\"Facility Sleep Questionnaire Night Before\",\n",
    "                      \"biostats_derived_core_proc\":\"Biostats Derived Core\", \n",
    "                      \"biostats_derived_symptoms\":\"Biostats Derived Symptoms\", \"biostats_derived_visits\":\"Biostats Derived Visits\"\n",
    "                      }\n",
    "\n",
    "# visit_data, fitbit, miscellaneous_form_visit_data, biospecimens do not have redcap forms\n",
    "# biostats_ datasets are Derived data sets, these are split by visit \"visits_baseline_arm_1\" - take off \"arm_1\" as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map PIC-SURE dataset column via these mappings to create a new column\n",
    "for_df_instrum = []\n",
    "for dt in simplified['columnmeta_var_group_id']:\n",
    "    instrum = re.sub(\"enrollment_|followup_\\d{1,2}_|miscellaneous_form_|_baseline_arm_\\d{1,2}|_followup_\\d{1,2}_arm_\\d{1,2}\", '', dt)\n",
    "    if instrum in instrument_mapping.keys():\n",
    "        for_df_instrum.append(instrument_mapping[instrum])\n",
    "    else:\n",
    "        for_df_instrum.append('')\n",
    "\n",
    "df_instrum = pd.DataFrame({\"mapped_instrument\": for_df_instrum})\n",
    "#df_instrum.head()\n",
    "simplified_with_instrum = pd.concat([simplified, df_instrum], axis=1)\n",
    "simplified_with_instrum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvp = simplified_with_instrum[['columnmeta_var_id', 'columnmeta_description', 'columnmeta_var_group_id', 'columnmeta_var_group_description',\n",
    "                               'columnmeta_data_type', 'mapped_instrument', \n",
    "                               'HPDS_PATH', 'values']]\n",
    "mvp.columns = [\"Variable Name\", \"Variable Description\", \"Dataset\", \"Dataset Description\", \"Data Type\", \n",
    "               \"Mapped Instrument\", 'HPDS_PATH', \"values\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data dictionary functions\n",
    "\n",
    "def continuous(hpds_path, recover_results):\n",
    "    field_attributes = {}\n",
    "    if type(recover_results[hpds_path].min()) == np.float64:\n",
    "        field_attributes[\"min\"] = round(recover_results[hpds_path].min(), 2)\n",
    "        field_attributes[\"max\"] = round(recover_results[hpds_path].max(), 2)\n",
    "        field_attributes[\"mean\"] = round(recover_results[hpds_path].mean(), 2)\n",
    "    else:\n",
    "        field_attributes[\"min\"] = round(recover_results[hpds_path].min().iloc[0], 2)\n",
    "        field_attributes[\"max\"] = round(recover_results[hpds_path].max().iloc[0], 2)\n",
    "        field_attributes[\"mean\"] = round(recover_results[hpds_path].mean().iloc[0], 2)\n",
    "    return field_attributes\n",
    "\n",
    "def categorical(hpds_path, recover_results, data_dict):\n",
    "    field_attributes = {}\n",
    "    pattern = r'^\\d{4}-\\d{2}-\\d{2}$'\n",
    "    row = data_dict[data_dict.HPDS_PATH == hpds_path]\n",
    "    #print(list(row[\"values\"].iloc[0]))\n",
    "    if \"participant_id\" in row[\"Variable Name\"].iloc[0]:\n",
    "        field_attributes = \"ID\"\n",
    "    elif len(row[\"values\"]) > 0 and bool(re.match(pattern, list(row[\"values\"].iloc[0])[0])):\n",
    "        field_attributes = \"Date\"\n",
    "    elif len(row[\"values\"]) > 0:\n",
    "        row_values = list(row[\"values\"].iloc[0])\n",
    "        #print(row_values)\n",
    "        for cat in row_values:\n",
    "            if cat == \"false\":\n",
    "                field_attributes[False] = sum(recover_results[hpds_path] == False)\n",
    "            elif cat == \"true\":\n",
    "                field_attributes[True] = sum(recover_results[hpds_path] == True)\n",
    "            else:\n",
    "                try:\n",
    "                    field_attributes[cat] = sum(recover_results[hpds_path] == float(cat))\n",
    "                except:\n",
    "                    field_attributes[cat] = sum(recover_results[hpds_path] == cat)\n",
    "        if len(field_attributes) > 5:\n",
    "            field_attributes = dict(sorted(field_attributes.items(), key = lambda x: x[1], reverse = True)[:6])\n",
    "    return field_attributes\n",
    "\n",
    "# Code below to test functions\n",
    "#x = categorical(\"\\\\phs003463\\\\enrollment_covid_treatment\\\\rx_carelevel_enrollment_covid_treatment\\\\\", \n",
    "# recover_results, mvp)\n",
    "#print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cases for testing categorical options\n",
    "# True/False spcmn:st_whl_bldt1_3m_a \\\\phs003463\\\\biospecimens\\\\SPCMN:ST_WHL_BLDT1_3M_A\\\\\n",
    "# Multiple: alco_rxdrugspre_enrollment_alcohol_and_tobacco\n",
    "# More than 6: rx_carelevel_enrollment_covid_treatment \\\\phs003463\\\\enrollment_covid_treatment\\\\rx_carelevel_enrollment_covid_treatment\\\\\n",
    "# Participant ID: \\\\phs003463\\\\biospecimens\\\\participant_id\\\\\n",
    "# Date: alcofu_colldt_followup_4_alcohol_and_tobacco_followup  \\\\phs003463\\\\followup_4_alcohol_and_tobacco_followup\\\\alcofu_colldt_followup_4_alcohol_and_tobacco_followup\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data dictionary using above functions\n",
    "# Note - this chunk of code takes a while - about 15 mins\n",
    "\n",
    "num_participants_final = []\n",
    "field_attr_final = []\n",
    "\n",
    "for i, row in mvp.iterrows():\n",
    "    hpds_path = mvp.loc[i, \"HPDS_PATH\"]\n",
    "    d_type = mvp.loc[i, \"Data Type\"]\n",
    "    num_participant = recover_results[hpds_path].count()\n",
    "    num_participants_final.append(num_participant)\n",
    "    \n",
    "    if d_type == \"continuous\":\n",
    "        field_attr = continuous(hpds_path, recover_results)\n",
    "    if d_type == \"categorical\":\n",
    "        field_attr = categorical(hpds_path, recover_results, mvp)\n",
    "    \n",
    "    print(hpds_path)\n",
    "    print(field_attr)\n",
    "\n",
    "    field_attr_final.append(field_attr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add information to dataframe\n",
    "final_data_dict = pd.concat([mvp, pd.DataFrame({\"Number Participants\": num_participants_final}), \n",
    "                             pd.DataFrame({\"Field Attributes\": field_attr_final})], axis=1)\n",
    "final_data_dict = final_data_dict[['Variable Name', 'Variable Description', 'Dataset', 'Dataset Description', 'Data Type', 'Mapped Instrument', 'Number Participants', 'Field Attributes']]\n",
    "final_data_dict.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by datasets outlined above\n",
    "# Order enrollment enrollment, then enrollment demographics, then the other enrollment, then the follow up, then biospecimens, then fitbit\n",
    "comp = list(final_data_dict['Dataset'].unique())\n",
    "print(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After using a different tool to order the list, read in from text file and save as python list\n",
    "with open(\"ordered_list.txt\", \"r\") as instrum_list:\n",
    "\tlines = instrum_list.readlines()\n",
    "\t#print(lines)\n",
    "\n",
    "ordered_list = []\n",
    "for i in lines:\n",
    "\tas_list = i.split(\"\\n\")\n",
    "\tordered_list.append(as_list[0])\n",
    "\t\n",
    "print(ordered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to make sure none are missing\n",
    "for item in ordered_list:\n",
    "    if item not in comp:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT code to reorder df\n",
    "\n",
    "# Assume df is your pandas DataFrame with column \"Dataset\"\n",
    "# ordered_list is the list of datasets in the desired order\n",
    "\n",
    "# Create a categorical data type with the desired order\n",
    "cat_dtype = pd.CategoricalDtype(categories=ordered_list, ordered=True)\n",
    "\n",
    "# Convert the \"Dataset\" column to categorical with the desired order\n",
    "final_data_dict['Dataset'] = final_data_dict['Dataset'].astype(cat_dtype)\n",
    "\n",
    "# Sort the DataFrame based on the \"Dataset\" column\n",
    "df_sorted = final_data_dict.sort_values(by='Dataset')\n",
    "\n",
    "# Reset index if needed\n",
    "df_sorted.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Now df_sorted contains the DataFrame with rows ordered according to the ordered_list\n",
    "df_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted.to_csv(\"RECOVER_Adult_PIC-SURE_Data_Dictionary_with_values.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
